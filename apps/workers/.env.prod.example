# Eclaire Workers - Production Environment Configuration

# Application Environment
NODE_ENV=production
LOG_LEVEL=info

# Worker Configuration
WORKER_PORT=3002
WORKER_CONCURRENCY=5
AI_TIMEOUT=180000

# Redis Configuration (for Bull queues)
# Use Redis container name in custom network for production
REDIS_URL=redis://eclaire-redis:6379

# Backend API Configuration  
# Use backend container name in custom network for production
BACKEND_URL=http://eclaire-backend:3001
API_BASE_URL=http://eclaire-backend:3001

# External Services
# Use host.docker.internal for services running on host
DOCLING_SERVER_URL=http://host.docker.internal:5001

# Data Directories - Centralized
DATA_DIR=./data
USERS_DIR=./data/users
LOGS_DIR=./data/logs
BROWSER_DATA_DIR=/app/data/browser-data
CONFIG_DIR=./config

# Shared Storage Path
WORKER_SHARED_DATA_PATH=/app/data/users

# API keys used by workers (MUST be set for production)
# Generate secure API keys in the backend and copy them here
# Format: sk-{15 alphanumeric chars}-{32 alphanumeric chars}
WORKER_API_KEY=
AI_ASSISTANT_API_KEY=

# AI Configuration (Workers) - Active model selection is now in data/config/models.json
# The activeModel.workers setting in JSON config determines which model is used
AI_LOCAL_PROVIDER_URL=http://host.docker.internal:11435
# AI_PROXY_PROVIDER_URL=
# AI_PROXY_API_KEY=
AI_PROMPT_LOGGING_ENABLED=true

# REDDIT_CLIENT_ID=
# REDDIT_CLIENT_SECRET=

# Classic Github PAT, public_repo scope. (optional, for higher rate limits)
# GITHUB_TOKEN=